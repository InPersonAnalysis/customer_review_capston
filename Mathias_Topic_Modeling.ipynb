{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66ad7664-f72f-492b-a674-cfff52cf7cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "import wrangle\n",
    "\n",
    "pd.options.display.max_colwidth = None\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rc('figure', figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "842557cb-8a31-460c-b864-f5d90977c684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached csv file...\n"
     ]
    }
   ],
   "source": [
    "hotel = wrangle.wrangle_hotel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cf65b0-996c-4482-b27b-7baa39115e5a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83ddc96a-11b7-4a20-9e61-b0d809a6967c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_name</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>day_name</th>\n",
       "      <th>day</th>\n",
       "      <th>quarter</th>\n",
       "      <th>hotel_name</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>country</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>additional_number_of_scoring</th>\n",
       "      <th>average_score</th>\n",
       "      <th>total_number_of_reviews</th>\n",
       "      <th>reviewer_nationality</th>\n",
       "      <th>trip_type</th>\n",
       "      <th>nights_stayed</th>\n",
       "      <th>group_type</th>\n",
       "      <th>total_number_of_reviews_reviewer_has_given</th>\n",
       "      <th>reviewer_score</th>\n",
       "      <th>nps_group</th>\n",
       "      <th>days_since_review</th>\n",
       "      <th>neg_sentiment_score</th>\n",
       "      <th>neg_lem_sentiment_score</th>\n",
       "      <th>review_total_negative_word_counts</th>\n",
       "      <th>negative_unique_word_count</th>\n",
       "      <th>pos_sentiment_score</th>\n",
       "      <th>review_total_positive_word_counts</th>\n",
       "      <th>positive_unique_word_count</th>\n",
       "      <th>pos_lem_sentiment_score</th>\n",
       "      <th>negative_review</th>\n",
       "      <th>negative_clean_review</th>\n",
       "      <th>negative_stem</th>\n",
       "      <th>negative_lemma</th>\n",
       "      <th>positive_review</th>\n",
       "      <th>positive_clean_review</th>\n",
       "      <th>positive_stem</th>\n",
       "      <th>positive_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>August</td>\n",
       "      <td>8</td>\n",
       "      <td>2015</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Hilton London Metropole</td>\n",
       "      <td>225 Edgware Road Westminster Borough</td>\n",
       "      <td>London</td>\n",
       "      <td>W2 1JU</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>51.519569</td>\n",
       "      <td>-0.170521</td>\n",
       "      <td>1485</td>\n",
       "      <td>7.5</td>\n",
       "      <td>6977</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>leisure</td>\n",
       "      <td>2.0</td>\n",
       "      <td>group</td>\n",
       "      <td>4</td>\n",
       "      <td>7.5</td>\n",
       "      <td>passive</td>\n",
       "      <td>730</td>\n",
       "      <td>-0.1027</td>\n",
       "      <td>-0.1027</td>\n",
       "      <td>54</td>\n",
       "      <td>39</td>\n",
       "      <td>0.4019</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0.4019</td>\n",
       "      <td>First day the swimming pool was not opened therefore i could not access the facilities Finaly the receptionist fid not clarify that i would unable to move my car and did not stamp my car parking so i can come in and out Therefore i had to pay 50 for one day</td>\n",
       "      <td>first day swimmig pool ot opeed therefore could ot access facilities fialy receptioist fid ot clarify would uable move car ad ot stamp car parkig ca come ad therefore pay 50 oe day</td>\n",
       "      <td>first day swimmig pool ot ope therefor could ot access facil fiali receptioist fid ot clarifi would uabl move car ad ot stamp car parkig ca come ad therefor pay 50 oe day</td>\n",
       "      <td>first day swimmig pool ot opeed therefore could ot access facility fialy receptioist fid ot clarify would uable move car ad ot stamp car parkig ca come ad therefore pay 50 oe day</td>\n",
       "      <td>The hotel was clean and accessible</td>\n",
       "      <td>hotel clean accessible</td>\n",
       "      <td>hotel clean access</td>\n",
       "      <td>hotel clean accessible</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  month_name  month  year day_name  day  quarter               hotel_name  \\\n",
       "0     August      8  2015  Tuesday    4        3  Hilton London Metropole   \n",
       "\n",
       "                                 street    city zip_code         country  \\\n",
       "0  225 Edgware Road Westminster Borough  London   W2 1JU  United Kingdom   \n",
       "\n",
       "         lat       lng  additional_number_of_scoring  average_score  \\\n",
       "0  51.519569 -0.170521                          1485            7.5   \n",
       "\n",
       "   total_number_of_reviews reviewer_nationality trip_type  nights_stayed  \\\n",
       "0                     6977      United Kingdom    leisure            2.0   \n",
       "\n",
       "  group_type  total_number_of_reviews_reviewer_has_given  reviewer_score  \\\n",
       "0      group                                           4             7.5   \n",
       "\n",
       "  nps_group  days_since_review  neg_sentiment_score  neg_lem_sentiment_score  \\\n",
       "0   passive                730              -0.1027                  -0.1027   \n",
       "\n",
       "   review_total_negative_word_counts  negative_unique_word_count  \\\n",
       "0                                 54                          39   \n",
       "\n",
       "   pos_sentiment_score  review_total_positive_word_counts  \\\n",
       "0               0.4019                                  8   \n",
       "\n",
       "   positive_unique_word_count  pos_lem_sentiment_score  \\\n",
       "0                           6                   0.4019   \n",
       "\n",
       "                                                                                                                                                                                                                                                       negative_review  \\\n",
       "0   First day the swimming pool was not opened therefore i could not access the facilities Finaly the receptionist fid not clarify that i would unable to move my car and did not stamp my car parking so i can come in and out Therefore i had to pay 50 for one day    \n",
       "\n",
       "                                                                                                                                                                  negative_clean_review  \\\n",
       "0  first day swimmig pool ot opeed therefore could ot access facilities fialy receptioist fid ot clarify would uable move car ad ot stamp car parkig ca come ad therefore pay 50 oe day   \n",
       "\n",
       "                                                                                                                                                                negative_stem  \\\n",
       "0  first day swimmig pool ot ope therefor could ot access facil fiali receptioist fid ot clarifi would uabl move car ad ot stamp car parkig ca come ad therefor pay 50 oe day   \n",
       "\n",
       "                                                                                                                                                                       negative_lemma  \\\n",
       "0  first day swimmig pool ot opeed therefore could ot access facility fialy receptioist fid ot clarify would uable move car ad ot stamp car parkig ca come ad therefore pay 50 oe day   \n",
       "\n",
       "                        positive_review   positive_clean_review  \\\n",
       "0   The hotel was clean and accessible   hotel clean accessible   \n",
       "\n",
       "        positive_stem          positive_lemma  \n",
       "0  hotel clean access  hotel clean accessible  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotel.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2025ca-608e-495f-83f9-f86047eb6549",
   "metadata": {},
   "source": [
    "## Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd93c4a6-8dfd-4466-985b-4cc6b57ea325",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "234b4164-a926-4dcc-8f51-896646d4615b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pprint import pprint\n",
    "\n",
    "# # Gensim\n",
    "# import gensim\n",
    "# from gensim.models.ldamodel import LdaModel\n",
    "# import gensim.corpora as corpora\n",
    "# from gensim.utils import simple_preprocess\n",
    "# from gensim.models import CoherenceModel\n",
    "\n",
    "# # Plotting tools\n",
    "# import pyLDAvis\n",
    "# import pyLDAvis.gensim_models  # don't skip this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2f8d41a-0c1b-47ed-a768-c21c7fdc99f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = hotel.positive_lemma.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fbbb95a-4378-40f1-894a-0db3f5b1f902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sent_to_words(sentences):\n",
    "#     for sentence in sentences:\n",
    "#         yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "# data_words = list(sent_to_words(data))\n",
    "\n",
    "# print(data_words[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09709afe-2628-4aa3-b8b4-d448ef729eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create Dictionary\n",
    "# id2word = corpora.Dictionary(data_words)\n",
    "\n",
    "# # Create Corpus\n",
    "# texts = data_words\n",
    "\n",
    "# # Term Document Frequency\n",
    "# corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# # View\n",
    "# print(corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cf24d3a-60ff-4b76-ab6d-631d36c322a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# id2word[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "004f45a0-b442-4ba1-819d-65826ab6ab36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Human readable format of corpus (term-frequency)\n",
    "# [[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2549980-575d-42e7-acc5-146769808cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "# lda_model = LdaModel(corpus=corpus,id2word=id2word,\n",
    "#                     num_topics=10, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ce2c802-5a20-40bd-a552-4e6896f7498c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "# pprint(lda_model.print_topics())\n",
    "# doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86284fd9-ea8f-453b-9b0a-1caea9510bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5df7053d-f1b3-45e1-baad-d7e5fcd245e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute Perplexity\n",
    "# print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# # Compute Coherence Score\n",
    "# coherence_model_lda = CoherenceModel(model=lda_model, texts=data_words, dictionary=id2word)\n",
    "# coherence_lda = coherence_model_lda.get_coherence()\n",
    "# print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65c38422-ae34-4b83-a2e8-0dc4854556e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "# pyLDAvis.enable_notebook()\n",
    "# vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word)\n",
    "# vis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97d75ae-d789-415d-82cc-7824201b849e",
   "metadata": {},
   "source": [
    "## SKLearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f9f107-4bd7-4588-87ff-5990bf2b0f12",
   "metadata": {},
   "source": [
    "## Positive topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b6ec15c-237e-47ff-a6b9-f930982c028c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, gensim\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pprint import pprint\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a90a04f-6ccd-4b0e-8b3e-6caf9ac87e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = hotel.positive_lemma.dropna().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "851dd63d-97ee-44b9-8112-4eee86fe97e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fbc6d9c4-51f6-40bf-9841-cd660572b1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('countvec.csv', 'wb') as f:\n",
    "    pickle.dump(vectorizer, f)\n",
    "    \n",
    "with open('countvec.csv', 'rb') as f:\n",
    "    vectorizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b66e370-f5c9-4d6b-baae-135cd2606bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vectorized = vectorizer.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fc7ccb-40a4-4573-871d-c0ef345c5751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA Model\n",
    "lda_model = LatentDirichletAllocation(learning_method='online',   \n",
    "                                      random_state=172,\n",
    "                                      n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960964ec-dd17-48f7-ba4c-07f7a8fdb5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_output = lda_model.fit_transform(data_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679c89f4-c6c1-41d7-9f5f-ce1f1524b1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lda.csv', 'wb') as f:\n",
    "    pickle.dump(lda_model, f)\n",
    "    \n",
    "with open('lda.csv', 'rb') as f:\n",
    "    lda_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3447bd90-faea-4bee-b943-96596eefaa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Materialize the sparse data\n",
    "data_dense = data_vectorized.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62ea28e-b4f4-46b5-a004-15864a8cebad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Sparsicity = Percentage of Non-Zero cells\n",
    "print(\"Sparsicity: \", ((data_dense > 0).sum()/data_dense.size)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f2cb2e-ea22-4b91-a7a6-f1131ea21f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log Likelyhood: Higher the better\n",
    "print(\"Log Likelihood: \", lda_model.score(data_vectorized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547a203a-6295-44a8-8c66-6b63ca59639d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perplexity: Lower the better. Perplexity = exp(-1. * log-likelihood per word)\n",
    "print(\"Perplexity: \", lda_model.perplexity(data_vectorized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c085cd2a-6aa3-4b4f-97c4-389862dae6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See model parameters\n",
    "pprint(lda_model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a996cdfe-fb19-4224-ac51-eec79252c842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Document - Topic Matrix\n",
    "lda_output = lda_model.transform(data_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cabdc67-515d-44ae-abbc-a18ec4ae88fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column names\n",
    "topicnames = [\"Topic\" + str(i) for i in range(lda_model.n_components)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadefa7a-86ce-42b6-afd7-e506093b6f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index names\n",
    "docnames = [\"Doc\" + str(i) for i in range(len(data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c54c8a-b7eb-4cfe-b2d5-73a5af1bc59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the pandas dataframe\n",
    "df_document_topic = pd.DataFrame(np.round(lda_output, 2), columns=topicnames, index=docnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268479e1-4f0b-4394-b130-8b901be9b17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dominant topic for each document\n",
    "dominant_topic = np.argmax(df_document_topic.values, axis=1)\n",
    "df_document_topic['dominant_topic'] = dominant_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a647435-9368-4af5-89dc-7e824af44f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Styling\n",
    "def color_green(val):\n",
    "    color = 'green' if val > .1 else 'black'\n",
    "    return 'color: {col}'.format(col=color)\n",
    "\n",
    "def make_bold(val):\n",
    "    weight = 700 if val > .1 else 400\n",
    "    return 'font-weight: {weight}'.format(weight=weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc663770-66c7-4421-aad4-f2b3ac43d9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Style\n",
    "df_document_topics = df_document_topic.head(15).style.applymap(color_green).applymap(make_bold)\n",
    "df_document_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bcb5a3-95a4-47b1-b319-7289324b965b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_distribution = df_document_topic['dominant_topic'].value_counts().reset_index(name=\"Num Documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f481524-78dc-46cd-9088-20b6d52bfd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_distribution.columns = ['Topic Num', 'Num Documents']\n",
    "df_topic_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e5b409-03f2-4198-9a82-88f50416f0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "panel = pyLDAvis.sklearn.prepare(lda_model, data_vectorized, vectorizer, mds='tsne')\n",
    "panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5e29ac-a330-4f9e-b04a-c2d8fca1bd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic-Keyword Matrix\n",
    "df_topic_keywords = pd.DataFrame(lda_model.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a642613b-3f1d-4bff-8145-38e4e595c650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign Column and Index\n",
    "df_topic_keywords.columns = vectorizer.get_feature_names()\n",
    "df_topic_keywords.index = topicnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce83872-1e76-40c2-b623-01e7be927639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View\n",
    "df_topic_keywords.head()sort_.sort_values(ascending=False,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7346226d-e4a1-456f-8053-6ae63b82218a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show top n keywords for each topic\n",
    "def show_topics(vectorizer=vectorizer, lda_model=lda_model, n_words=20):\n",
    "    keywords = np.array(vectorizer.get_feature_names())\n",
    "    topic_keywords = []\n",
    "    for topic_weights in lda_model.components_:\n",
    "        top_keyword_locs = (-topic_weights).argsort()[:n_words]\n",
    "        topic_keywords.append(keywords.take(top_keyword_locs))\n",
    "    return topic_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfabd31e-8c6e-4372-a0b5-5403340eaa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_keywords = show_topics(vectorizer=vectorizer, lda_model=lda_model, n_words=15)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6915ec97-7c9d-4004-a3b0-662762d8a290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic - Keywords Dataframe\n",
    "df_topic_keywords = pd.DataFrame(topic_keywords)\n",
    "df_topic_keywords.columns = ['Word '+str(i) for i in range(df_topic_keywords.shape[1])]\n",
    "df_topic_keywords.index = ['Topic '+str(i) for i in range(df_topic_keywords.shape[0])]\n",
    "df_topic_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cfbe2a-1df8-4585-9619-3768d932ce3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the k-means clusters\n",
    "from sklearn.cluster import KMeans\n",
    "clusters = KMeans(n_clusters=15, random_state=100).fit_predict(lda_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a09a2b-e935-4cb8-9056-7bf3d842762f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Singular Value Decomposition(SVD) model\n",
    "svd_model = TruncatedSVD(n_components=2)  # 2 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1085f22d-3c79-495e-88a5-ef512faf1128",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_output_svd = svd_model.fit_transform(lda_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb321b8-93a1-4b87-8611-469fb783a4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X and Y axes of the plot using SVD decomposition\n",
    "x = lda_output_svd[:, 0]\n",
    "y = lda_output_svd[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664dfbe4-654f-486f-b420-bfba155d5e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights for the 15 columns of lda_output, for each component\n",
    "print(\"Component's weights: \\n\", np.round(svd_model.components_, 2))\n",
    "\n",
    "# Percentage of total information in 'lda_output' explained by the two components\n",
    "print(\"Perc of Variance Explained: \\n\", np.round(svd_model.explained_variance_ratio_, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af35b464-7d18-4ce1-a59f-cfdf457ef1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.scatter(x, y, c=clusters)\n",
    "plt.xlabel('Component 2')\n",
    "plt.xlabel('Component 1')\n",
    "plt.title(\"Segregation of Topic Clusters\", )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9308e54-7aa1-4492-8869-6466d4c8418a",
   "metadata": {},
   "source": [
    "## Negative Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b824a8e-8319-4b2e-93bb-cbd851b7cca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_data = hotel.negative_lemma.dropna().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d618a64-9cc6-4abe-a87c-b93d8c0629a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8971b9-41ad-401e-a8cf-70c2120d1a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('negative_countvec.csv', 'wb') as f:\n",
    "    pickle.dump(negative_vectorizer, f)\n",
    "    \n",
    "with open('negative_countvec.csv', 'rb') as f:\n",
    "    negative_vectorizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ef773b-d884-4a1e-a3c6-113be7cc1ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_data_vectorized = vectorizer.fit_transform(negative_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0646c9b-1ca1-4d95-a5a1-db0dd812e513",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build LDA Model\n",
    "negative_lda_model = LatentDirichletAllocation(learning_method='online',   \n",
    "                                      random_state=172,\n",
    "                                      n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb170a0-9107-4552-bc3c-c3d584fd609d",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_lda_output = negative_lda_model.fit_transform(negative_data_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b714542-85d4-467b-88f6-8118bbaf8b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('negative_lda.csv', 'wb') as f:\n",
    "    pickle.dump(negative_lda_model, f)\n",
    "    \n",
    "with open('negative_lda.csv', 'rb') as f:\n",
    "    negative_lda_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5834f85-8e3c-4b93-adc3-53623fdbd2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Materialize the sparse data\n",
    "negative_data_dense = negative_data_vectorized.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16adba1a-b443-499e-a3d1-a4c511560466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Sparsicity = Percentage of Non-Zero cells\n",
    "print(\"Sparsicity: \", ((negative_data_dense > 0).sum()/negative_data_dense.size)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9306c9-87b9-4f74-a169-41467bdcf1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log Likelyhood: Higher the better\n",
    "print(\"Log Likelihood: \", negative_lda_model.score(negative_data_vectorized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36777d6f-2e09-4a0e-a261-72247033718a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perplexity: Lower the better. Perplexity = exp(-1. * log-likelihood per word)\n",
    "print(\"Perplexity: \", negative_lda_model.perplexity(negative_data_vectorized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cce830-83cd-4c4b-a72a-a7cde63ae898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See model parameters\n",
    "pprint(negative_lda_model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b294bc-0f5d-424a-b23f-c707db9f31b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Document - Topic Matrix\n",
    "negative_lda_output = negative_lda_model.transform(negative_data_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27f0449-46da-476b-9c27-45f94558a639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column names\n",
    "negative_topicnames = [\"Topic\" + str(i) for i in range(negative_lda_model.n_components)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158677d9-57e6-4fbe-a03f-7f877d922630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index names\n",
    "negative_docnames = [\"Doc\" + str(i) for i in range(len(negative_data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f291e17b-085d-45ca-8d60-9673794b2748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the pandas dataframe\n",
    "negative_df_document_topic = pd.DataFrame(np.round(negative_lda_output, 2), columns=negative_topicnames, index=negative_docnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b5bc65-356e-48f2-8a58-4aaa92bdccb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dominant topic for each document\n",
    "negative_dominant_topic = np.argmax(negative_df_document_topic.values, axis=1)\n",
    "negative_df_document_topic['dominant_topic'] = neagtive_dominant_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c858f62-8807-4d26-bd0b-8bff2a169324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Styling\n",
    "def color_green(val):\n",
    "    color = 'green' if val > .1 else 'black'\n",
    "    return 'color: {col}'.format(col=color)\n",
    "\n",
    "def make_bold(val):\n",
    "    weight = 700 if val > .1 else 400\n",
    "    return 'font-weight: {weight}'.format(weight=weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863ce195-6b21-4427-9b89-c1036b3c8f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Style\n",
    "negative_df_document_topics = negative_df_document_topic.head(15).style.applymap(color_green).applymap(make_bold)\n",
    "negative_df_document_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cdf113-e1a5-4b47-a982-6b582e84c9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_df_topic_distribution = negative_df_document_topic['dominant_topic'].value_counts().reset_index(name=\"Num Documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7888588-dd1d-4861-9ccb-1a69de55b5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_df_topic_distribution.columns = ['Topic Num', 'Num Documents']\n",
    "negative_df_topic_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ffdaa7-8af1-4d9c-9d1d-25ee09545ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "negative_panel = pyLDAvis.sklearn.prepare(negative_lda_model, negative_data_vectorized, vectorizer, mds='tsne')\n",
    "negative_panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bad52ef-c3d4-47dc-81b9-73e69c01db2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic-Keyword Matrix\n",
    "negative_df_topic_keywords = pd.DataFrame(negative_lda_model.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb7c334-3c01-4fed-8921-76359f2ea99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign Column and Index\n",
    "negative_df_topic_keywords.columns = negative_vectorizer.get_feature_names()\n",
    "negative_df_topic_keywords.index = negative_topicnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84504bcf-d1b1-4bdf-8e01-ef19ef53f6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View\n",
    "negative_df_topic_keywords.head()sort_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5bf34b-8548-4622-838c-1eada3b219c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show top n keywords for each topic\n",
    "def show_topics(vectorizer=negative_vectorizer, lda_model=negative_lda_model, n_words=20):\n",
    "    keywords = np.array(negative_vectorizer.get_feature_names())\n",
    "    topic_keywords = []\n",
    "    for topic_weights in negative_lda_model.components_:\n",
    "        top_keyword_locs = (-topic_weights).argsort()[:n_words]\n",
    "        topic_keywords.append(keywords.take(top_keyword_locs))\n",
    "    return topic_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae16226e-9f00-47c1-9cc0-4294e4de1cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_topic_keywords = show_topics(vectorizer=negative_vectorizer, lda_model=negative_lda_model, n_words=15)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd9cc28-0cca-4fbd-96f3-b6ffa4903f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic - Keywords Dataframe\n",
    "negative_df_topic_keywords = pd.DataFrame(negative_topic_keywords)\n",
    "negative_df_topic_keywords.columns = ['Word '+str(i) for i in range(negative_df_topic_keywords.shape[1])]\n",
    "negative_df_topic_keywords.index = ['Topic '+str(i) for i in range(negative_df_topic_keywords.shape[0])]\n",
    "negative_df_topic_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e88b8a-348d-40f2-8ee2-8b08a8f7566a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the k-means clusters\n",
    "from sklearn.cluster import KMeans\n",
    "negative_clusters = KMeans(n_clusters=15, random_state=100).fit_predict(negative_lda_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a83a9a8-e407-40d5-8045-2d78496a14fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Singular Value Decomposition(SVD) model\n",
    "negative_svd_model = TruncatedSVD(n_components=2)  # 2 components\n",
    "negative_lda_output_svd = negative_svd_model.fit_transform(negative_lda_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd73f2a7-8bb4-45b3-95bc-6892bad79c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X and Y axes of the plot using SVD decomposition\n",
    "negative_x = negative_lda_output_svd[:, 0]\n",
    "negative_y = negative_lda_output_svd[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6a1146-401b-482d-9967-79135df41db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights for the 15 columns of lda_output, for each component\n",
    "print(\"Component's weights: \\n\", np.round(negative_svd_model.components_, 2))\n",
    "\n",
    "# Percentage of total information in 'lda_output' explained by the two components\n",
    "print(\"Perc of Variance Explained: \\n\", np.round(negative_svd_model.explained_variance_ratio_, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f009d9-5096-4e89-bb13-68564721e185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.scatter(negative_x, negative_y, c=clusters)\n",
    "plt.xlabel('Component 2')\n",
    "plt.xlabel('Component 1')\n",
    "plt.title(\"Segregation of Topic Clusters\", )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cbebf1-3929-4e8e-b099-02019291eb00",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dc3731-c0fe-425a-a8c6-ff5ec020cd38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Define Search Param\n",
    "# search_params = {'n_components': [10, 20, 30], 'learning_decay': [.5, .7, .9]}\n",
    "\n",
    "# # Init the Model\n",
    "# lda = LatentDirichletAllocation()\n",
    "\n",
    "# with open('lda.csv', 'wb') as f:\n",
    "#     pickle.dump(lda, f)\n",
    "    \n",
    "# with open('lda.csv', 'rb') as f:\n",
    "#     lda = pickle.load(f)\n",
    "    \n",
    "# # Init Grid Search Class\n",
    "# model = GridSearchCV(lda, param_grid=search_params)\n",
    "\n",
    "# with open('grid.csv', 'wb') as f:\n",
    "#     pickle.dump(model, f)\n",
    "    \n",
    "# with open('grid.csv', 'rb') as f:\n",
    "#     model = pickle.load(f)\n",
    "    \n",
    "# # Do the Grid Search\n",
    "# model.fit(data_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9864a4e2-390b-4d28-bd7f-55203ae7f145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Best Model\n",
    "# best_lda_model = model.best_estimator_\n",
    "\n",
    "# # Model Parameters\n",
    "# print(\"Best Model's Params: \", model.best_params_)\n",
    "\n",
    "# # Log Likelihood Score\n",
    "# print(\"Best Log Likelihood Score: \", model.best_score_)\n",
    "\n",
    "# # Perplexity\n",
    "# print(\"Model Perplexity: \", best_lda_model.perplexity(data_vectorized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48100ee5-48b1-4345-b24c-55d6932940a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get Log Likelyhoods from Grid Search Output\n",
    "# n_topics = [10, 15, 20, 25, 30]\n",
    "# log_likelyhoods_5 = [round(gscore.mean_validation_score) for gscore in model.grid_scores_ if gscore.parameters['learning_decay']==0.5]\n",
    "# log_likelyhoods_7 = [round(gscore.mean_validation_score) for gscore in model.grid_scores_ if gscore.parameters['learning_decay']==0.7]\n",
    "# log_likelyhoods_9 = [round(gscore.mean_validation_score) for gscore in model.grid_scores_ if gscore.parameters['learning_decay']==0.9]\n",
    "\n",
    "# # Show graph\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# plt.plot(n_topics, log_likelyhoods_5, label='0.5')\n",
    "# plt.plot(n_topics, log_likelyhoods_7, label='0.7')\n",
    "# plt.plot(n_topics, log_likelyhoods_9, label='0.9')\n",
    "# plt.title(\"Choosing Optimal LDA Model\")\n",
    "# plt.xlabel(\"Num Topics\")\n",
    "# plt.ylabel(\"Log Likelyhood Scores\")\n",
    "# plt.legend(title='Learning decay', loc='best')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b83e5ef-9f63-4f66-b789-5b2471d8334e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3081ce-8691-499f-861a-a90e67bda0b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba61411b-9d43-4011-b729-95268978e3c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc6d809-1b46-496d-92b9-3097d32c6c67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
